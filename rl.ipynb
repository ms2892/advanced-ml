{"cells":[{"cell_type":"markdown","metadata":{"id":"b99Bt9NlTFxs"},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-09T20:03:55.953970Z","iopub.status.busy":"2023-03-09T20:03:55.953393Z","iopub.status.idle":"2023-03-09T20:03:56.038895Z","shell.execute_reply":"2023-03-09T20:03:56.037319Z","shell.execute_reply.started":"2023-03-09T20:03:55.953926Z"},"trusted":true},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-09T20:03:56.041904Z","iopub.status.busy":"2023-03-09T20:03:56.041405Z","iopub.status.idle":"2023-03-09T20:04:01.031194Z","shell.execute_reply":"2023-03-09T20:04:01.029632Z","shell.execute_reply.started":"2023-03-09T20:03:56.041863Z"},"id":"lfKcmk8-IzLN","trusted":true},"outputs":[],"source":["import urllib\n","\n","from sklearn.preprocessing import OneHotEncoder\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","from tqdm.notebook import tqdm"]},{"cell_type":"markdown","metadata":{"id":"z-JzHG4lakd9"},"source":["## Config"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-09T20:04:01.037309Z","iopub.status.busy":"2023-03-09T20:04:01.036054Z","iopub.status.idle":"2023-03-09T20:04:01.100591Z","shell.execute_reply":"2023-03-09T20:04:01.098950Z","shell.execute_reply.started":"2023-03-09T20:04:01.037226Z"},"id":"GLiIUez0ajw3","trusted":true},"outputs":[],"source":["BUFFER_SIZE = 4096\n","BATCH_SIZE = 64\n","EPS = 0.0\n","LEARNING_RATE = 1e-3\n","N_TRAINING_STEPS = 50000"]},{"cell_type":"markdown","metadata":{"id":"WpEvaGA7TEuM"},"source":["## Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-09T20:04:01.106129Z","iopub.status.busy":"2023-03-09T20:04:01.105547Z","iopub.status.idle":"2023-03-09T20:04:02.845024Z","shell.execute_reply":"2023-03-09T20:04:02.842917Z","shell.execute_reply.started":"2023-03-09T20:04:01.106060Z"},"id":"NWwTsXNgIkDK","outputId":"07ed168a-1359-4155-8b66-d2394dd59c1d","trusted":true},"outputs":[],"source":["urllib.request.urlretrieve(\n","    \"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\",\n","    \"agaricus-lepiota.data\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-09T20:04:02.848155Z","iopub.status.busy":"2023-03-09T20:04:02.847635Z","iopub.status.idle":"2023-03-09T20:04:03.171831Z","shell.execute_reply":"2023-03-09T20:04:03.170091Z","shell.execute_reply.started":"2023-03-09T20:04:02.848106Z"},"id":"-gekDkFaLvA5","outputId":"f40416a0-b4d0-47e8-ee3f-2f912c5e08f1","trusted":true},"outputs":[],"source":["df = pd.read_csv(\"agaricus-lepiota.data\", header=None)\n","\n","# Find the labels\n","labels = df.pop(df.columns[0])\n","labels = pd.Categorical(labels, categories=[\"p\", \"e\"]).codes\n","labels\n","\n","# Get the contexts\n","for col in df:\n","    df[col] = pd.Categorical(df[col]).codes\n","contexts = OneHotEncoder(sparse=False, dtype=np.float32).fit_transform(df)\n","\n","# Convert to torch tensors\n","contexts = torch.tensor(contexts)\n","labels = torch.tensor(labels, dtype=bool)\n","\n","contexts, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-09T20:04:03.175437Z","iopub.status.busy":"2023-03-09T20:04:03.174806Z","iopub.status.idle":"2023-03-09T20:04:03.230925Z","shell.execute_reply":"2023-03-09T20:04:03.229261Z","shell.execute_reply.started":"2023-03-09T20:04:03.175371Z"},"id":"-wU34VGpUqLE","outputId":"eecc2419-f59c-4fc5-c83a-7aab9cb23e30","trusted":true},"outputs":[],"source":["contexts.shape, labels.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-09T20:04:03.236069Z","iopub.status.busy":"2023-03-09T20:04:03.234291Z","iopub.status.idle":"2023-03-09T20:04:03.292286Z","shell.execute_reply":"2023-03-09T20:04:03.290214Z","shell.execute_reply.started":"2023-03-09T20:04:03.235998Z"},"trusted":true},"outputs":[],"source":["contexts.dtype, labels.dtype"]},{"cell_type":"markdown","metadata":{"id":"UvtuXSYxTIc7"},"source":["## Environment"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-09T20:04:03.296249Z","iopub.status.busy":"2023-03-09T20:04:03.294362Z","iopub.status.idle":"2023-03-09T20:04:03.353985Z","shell.execute_reply":"2023-03-09T20:04:03.352310Z","shell.execute_reply.started":"2023-03-09T20:04:03.296172Z"},"id":"7OcdTTcfPicp","trusted":true},"outputs":[],"source":["class Environment:\n","\n","    def __init__(self, contexts, labels):\n","        self.contexts = contexts\n","        self.labels = labels\n","    \n","    def get_random_mushroom(self):\n","        mushroom_idx = np.random.randint(len(self.contexts))\n","\n","        return self.contexts[mushroom_idx], self.labels[mushroom_idx].item()\n","\n","    def get_agent_reward(self, edible, eaten):\n","        if not eaten:\n","            return 0\n","        if edible:\n","            return 5\n","        if torch.rand(1).item() <= 0.5:\n","            return -35\n","        return 5\n","    \n","    def get_oracle_reward(self, edible):\n","        return 5 * float(edible)\n"]},{"cell_type":"markdown","metadata":{"id":"qu8Ug8t2U2kG"},"source":["## Agent"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-09T20:04:03.356523Z","iopub.status.busy":"2023-03-09T20:04:03.355760Z","iopub.status.idle":"2023-03-09T20:04:03.423985Z","shell.execute_reply":"2023-03-09T20:04:03.422788Z","shell.execute_reply.started":"2023-03-09T20:04:03.356471Z"},"id":"vsAlvtviVhIc","trusted":true},"outputs":[],"source":["class Agent:\n","\n","    def __init__(\n","            self, model, optimizer, batch_size,\n","            eps=0.0, buffer_size=4096, context_size=117,\n","        ):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.batch_size = batch_size\n","        \n","        self.eps = eps\n","        print(f\"eps={self.eps}\")\n","        \n","        self.buffer_size = buffer_size\n","        self.context_action_buffer = torch.zeros(buffer_size, context_size + 2)\n","        self.reward_buffer = torch.zeros(buffer_size)\n","        \n","        self.tp = 0\n","        self.tn = 0\n","        self.fp = 0\n","        self.fn = 0\n","        \n","        self.tps = []\n","        self.tns = []\n","        self.fps = []\n","        self.fns = []\n","        \n","        self.decisions = []\n","\n","\n","    def step(self, mushroom_context):\n","        eat_action = torch.hstack([mushroom_context, torch.tensor([1, 0])])\n","        not_eat_action = torch.hstack([mushroom_context, torch.tensor([0, 1])])\n","\n","        self.model.eval()\n","        with torch.no_grad():\n","            eat_reward = self.model(eat_action).item()\n","            not_eat_reward = self.model(not_eat_action).item()\n","        \n","        # Action is to eat or not\n","        eat = eat_reward > not_eat_reward\n","        if np.random.rand() <= self.eps:\n","            eat = np.random.rand() <= 0.5\n","        \n","        return eat\n","    \n","\n","    def update_buffers(self, context_action_pair, reward, step, edible, eat):\n","        new_idx = step % self.buffer_size\n","        self.context_action_buffer[new_idx, :] = context_action_pair\n","        self.reward_buffer[new_idx] = reward\n","        \n","        # record bandit action\n","        if edible and eat:\n","            self.tp += 1\n","        elif edible and not eat:\n","            self.fn += 1\n","        elif not edible and eat:\n","            self.fp += 1\n","        else:\n","            self.tn += 1\n","        \n","        self.tps.append(self.tp)\n","        self.tns.append(self.tn)\n","        self.fps.append(self.fp)\n","        self.fns.append(self.fn)\n","        \n","        self.decisions.append(eat)\n","\n","\n","    def _get_training_dataloader(self, step):\n","        max_idx = min(step, self.buffer_size)\n","        \n","        training_context_action_pairs = self.context_action_buffer[:max_idx, :]\n","        training_rewards = self.reward_buffer[:max_idx]\n","\n","        if max_idx < self.buffer_size:\n","            indices = torch.randint(\n","                high=training_context_action_pairs.shape[0], size=(self.buffer_size, ),\n","            )\n","            training_context_action_pairs = training_context_action_pairs[indices]\n","            training_rewards = training_rewards[indices]\n","\n","        dataset = TensorDataset(training_context_action_pairs, training_rewards)\n","\n","        return DataLoader(\n","            dataset=dataset, batch_size=self.batch_size,\n","            shuffle=True, drop_last=False, num_workers=0,\n","        )\n","\n","\n","    def train(self, step):\n","        dataloader = self._get_training_dataloader(step=step)\n","\n","        running_loss = 0\n","        self.model.train()\n","        for x, y in dataloader:\n","            predicted_rewards = self.model(x).squeeze(dim=-1)\n","            loss = F.mse_loss(input=predicted_rewards, target=y)\n","\n","            self.optimizer.zero_grad()\n","            loss.backward()\n","            self.optimizer.step()\n","\n","            running_loss += loss.item() * len(y)\n","\n","        return running_loss / len(dataloader.dataset)"]},{"cell_type":"markdown","metadata":{"id":"-yRzb5JqVzJY"},"source":["## Trainer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-09T20:12:52.978727Z","iopub.status.busy":"2023-03-09T20:12:52.978126Z","iopub.status.idle":"2023-03-09T20:12:53.040737Z","shell.execute_reply":"2023-03-09T20:12:53.038965Z","shell.execute_reply.started":"2023-03-09T20:12:52.978655Z"},"id":"zfWJOLVCVx4k","trusted":true},"outputs":[],"source":["def train_rl(n_steps, environment, agent, name, scheduler=None):\n","\n","    cumulative_regrets = [0]\n","    losses = []\n","\n","    loop = tqdm(range(1, n_steps+1), total=n_steps, leave=False)\n","    for step in loop:\n","        # Get a new mushroom\n","        mushroom_context, edible = environment.get_random_mushroom()\n","\n","        # Decide whether to eat it\n","        eat = agent.step(mushroom_context=mushroom_context)\n","\n","        # Calculate the different reward\n","        agent_reward = environment.get_agent_reward(edible=edible, eaten=eat)\n","        oracle_reward = environment.get_oracle_reward(edible=edible)\n","\n","        # Update the buffers\n","        action = torch.Tensor([1, 0] if eat else [0, 1])\n","        agent.update_buffers(\n","            context_action_pair=torch.hstack([mushroom_context, action]),\n","            reward=agent_reward,\n","            step=step-1,\n","            edible=edible,\n","            eat=eat,\n","        )\n","\n","        # Calculate regret\n","        regret = oracle_reward - agent_reward\n","        cumulative_regrets.append(cumulative_regrets[-1] + regret)\n","\n","        loss = agent.train(step=step)\n","        losses.append(loss)\n","    \n","        if scheduler is not None:\n","            scheduler.step()\n","            loop.set_postfix(\n","                cumulative_regret=cumulative_regrets[-1], loss=loss,\n","                lr=scheduler._last_lr[0]\n","            )\n","        else:\n","            loop.set_postfix(\n","                cumulative_regret=cumulative_regrets[-1], loss=loss,\n","            )\n","        \n","        if step % (n_steps // 50) == 0:\n","            print(f\"Step {step}: regret: {cumulative_regrets[-1]} ({len(cumulative_regrets[1:])})\")\n","            print(f\"TP: {agent.tp}, TN: {agent.tn}, FP: {agent.fp}, FN: {agent.fn}\")\n","            df = pd.DataFrame.from_dict({\n","                \"cumulative_regrets\": cumulative_regrets[1:],\n","                \"losses\": losses\n","            })\n","            df.to_csv(f\"{name}.csv\")\n","            \n","            save_dict = {\n","                \"model\": agent.model.state_dict(),\n","                \"optimizer\": agent.optimizer.state_dict(),\n","                \"agent\": agent,\n","                \"cumulative_regrets\": cumulative_regrets,\n","            }\n","            if scheduler is not None: save_dict[\"scheduler\"] = scheduler.state_dict()\n","            torch.save(save_dict, f\"checkpoint_{step}.ckpt\")\n","    \n","    return cumulative_regrets[1:], losses"]},{"cell_type":"markdown","metadata":{"id":"32ossZi1jPFK"},"source":["## Run"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-09T20:12:53.311094Z","iopub.status.busy":"2023-03-09T20:12:53.310613Z","iopub.status.idle":"2023-03-09T20:12:53.360652Z","shell.execute_reply":"2023-03-09T20:12:53.359062Z","shell.execute_reply.started":"2023-03-09T20:12:53.311055Z"},"trusted":true},"outputs":[],"source":["def init_weights(m):\n","    if isinstance(m, nn.Linear):\n","        nn.init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n","        m.bias.data.fill_(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-09T20:16:04.147761Z","iopub.status.busy":"2023-03-09T20:16:04.146653Z","iopub.status.idle":"2023-03-09T20:25:16.108397Z","shell.execute_reply":"2023-03-09T20:25:16.106811Z","shell.execute_reply.started":"2023-03-09T20:16:04.147686Z"},"id":"7xb0_chCZ6Bk","trusted":true},"outputs":[],"source":["%%time\n","\n","environment = Environment(contexts=contexts, labels=labels)\n","\n","model = nn.Sequential(\n","    nn.Linear(in_features=contexts.shape[1] + 2, out_features=100), nn.ReLU(),\n","    nn.Linear(in_features=100, out_features=100), nn.ReLU(),\n","    nn.Linear(in_features=100, out_features=1),\n",")\n","model.apply(init_weights)\n","print(f\"Number of model parameters: {sum(p.nelement() for p in model.parameters())}\")\n","\n","optimizer = torch.optim.SGD(\n","    params=model.parameters(), lr=LEARNING_RATE,\n","    momentum=0.9, nesterov=True,\n",")\n","print(optimizer)\n","\n","# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5000, gamma=0.5)\n","scheduler = None\n","\n","agent = Agent(\n","    model=model, optimizer=optimizer,\n","    batch_size=BATCH_SIZE,\n","    eps=EPS, buffer_size=BUFFER_SIZE,\n","    context_size=contexts.shape[1],\n",")\n","\n","print(\"Training\")\n","cumulative_regrets, losses = train_rl(\n","    n_steps=N_TRAINING_STEPS, environment=environment,\n","    agent=agent, scheduler=scheduler,\n","    name=f\"greedy_eps_{EPS}\",\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-09T20:25:16.111860Z","iopub.status.busy":"2023-03-09T20:25:16.111268Z","iopub.status.idle":"2023-03-09T20:25:16.166605Z","shell.execute_reply":"2023-03-09T20:25:16.165070Z","shell.execute_reply.started":"2023-03-09T20:25:16.111816Z"},"trusted":true},"outputs":[],"source":["cumulative_regrets[-10:]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-09T20:25:16.168684Z","iopub.status.busy":"2023-03-09T20:25:16.168294Z","iopub.status.idle":"2023-03-09T20:25:16.460093Z","shell.execute_reply":"2023-03-09T20:25:16.457923Z","shell.execute_reply.started":"2023-03-09T20:25:16.168643Z"},"id":"HN1twnQajVvU","trusted":true},"outputs":[],"source":["plt.plot(range(1, len(cumulative_regrets) + 1), cumulative_regrets)\n","plt.yscale(\"log\")\n","plt.grid()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-03-09T20:25:16.461226Z","iopub.status.idle":"2023-03-09T20:25:16.461748Z","shell.execute_reply":"2023-03-09T20:25:16.461517Z","shell.execute_reply.started":"2023-03-09T20:25:16.461492Z"},"id":"Rt5a60L7jWFZ","trusted":true},"outputs":[],"source":["plt.plot(range(1, len(losses) + 1), losses, \"-o\")\n","plt.grid()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
