{"cells":[{"cell_type":"markdown","metadata":{"id":"b99Bt9NlTFxs"},"source":["## Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-03-13T14:22:01.650129Z","iopub.status.busy":"2023-03-13T14:22:01.649542Z","iopub.status.idle":"2023-03-13T14:22:01.728083Z","shell.execute_reply":"2023-03-13T14:22:01.726368Z","shell.execute_reply.started":"2023-03-13T14:22:01.650072Z"},"trusted":true},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-03-13T14:22:01.731289Z","iopub.status.busy":"2023-03-13T14:22:01.730605Z","iopub.status.idle":"2023-03-13T14:22:06.123531Z","shell.execute_reply":"2023-03-13T14:22:06.121997Z","shell.execute_reply.started":"2023-03-13T14:22:01.731244Z"},"id":"lfKcmk8-IzLN","trusted":true},"outputs":[],"source":["import urllib\n","\n","from sklearn.preprocessing import OneHotEncoder\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.distributions as D\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","from tqdm.notebook import tqdm"]},{"cell_type":"markdown","metadata":{"id":"z-JzHG4lakd9"},"source":["## Config"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-03-13T14:22:06.126967Z","iopub.status.busy":"2023-03-13T14:22:06.126256Z","iopub.status.idle":"2023-03-13T14:22:06.181288Z","shell.execute_reply":"2023-03-13T14:22:06.179669Z","shell.execute_reply.started":"2023-03-13T14:22:06.126919Z"},"id":"GLiIUez0ajw3","trusted":true},"outputs":[],"source":["BUFFER_SIZE = 4096\n","BATCH_SIZE = 64\n","LEARNING_RATE = 5e-6\n","N_TRAINING_STEPS = 18000\n","N_SAMPLES = 2"]},{"cell_type":"markdown","metadata":{"id":"WpEvaGA7TEuM"},"source":["## Data"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-03-13T14:22:06.185430Z","iopub.status.busy":"2023-03-13T14:22:06.184428Z","iopub.status.idle":"2023-03-13T14:22:06.542142Z","shell.execute_reply":"2023-03-13T14:22:06.540789Z","shell.execute_reply.started":"2023-03-13T14:22:06.185349Z"},"id":"NWwTsXNgIkDK","outputId":"07ed168a-1359-4155-8b66-d2394dd59c1d","trusted":true},"outputs":[{"data":{"text/plain":["('agaricus-lepiota.data', <http.client.HTTPMessage at 0x7f35f8acedd0>)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["urllib.request.urlretrieve(\n","    \"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\",\n","    \"agaricus-lepiota.data\"\n",")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-03-13T14:22:06.545209Z","iopub.status.busy":"2023-03-13T14:22:06.544106Z","iopub.status.idle":"2023-03-13T14:22:06.853995Z","shell.execute_reply":"2023-03-13T14:22:06.852408Z","shell.execute_reply.started":"2023-03-13T14:22:06.545154Z"},"id":"-gekDkFaLvA5","outputId":"f40416a0-b4d0-47e8-ee3f-2f912c5e08f1","trusted":true},"outputs":[{"data":{"text/plain":["(tensor([[0., 0., 0.,  ..., 0., 1., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [1., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 1.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]]),\n"," tensor([False,  True,  True,  ...,  True, False,  True]))"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(\"agaricus-lepiota.data\", header=None)\n","\n","# Find the labels\n","labels = df.pop(df.columns[0])\n","labels = pd.Categorical(labels, categories=[\"p\", \"e\"]).codes\n","labels\n","\n","# Get the contexts\n","for col in df:\n","    df[col] = pd.Categorical(df[col]).codes\n","contexts = OneHotEncoder(sparse=False, dtype=np.float32).fit_transform(df)\n","\n","# Convert to torch tensors\n","contexts = torch.tensor(contexts)\n","labels = torch.tensor(labels, dtype=bool)\n","\n","contexts, labels"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-03-13T14:22:06.857329Z","iopub.status.busy":"2023-03-13T14:22:06.856323Z","iopub.status.idle":"2023-03-13T14:22:06.909433Z","shell.execute_reply":"2023-03-13T14:22:06.907950Z","shell.execute_reply.started":"2023-03-13T14:22:06.857260Z"},"id":"-wU34VGpUqLE","outputId":"eecc2419-f59c-4fc5-c83a-7aab9cb23e30","trusted":true},"outputs":[{"data":{"text/plain":["(torch.Size([8124, 117]), torch.Size([8124]))"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["contexts.shape, labels.shape"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-03-13T14:22:06.911846Z","iopub.status.busy":"2023-03-13T14:22:06.911113Z","iopub.status.idle":"2023-03-13T14:22:06.963840Z","shell.execute_reply":"2023-03-13T14:22:06.962349Z","shell.execute_reply.started":"2023-03-13T14:22:06.911799Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(torch.float32, torch.bool)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["contexts.dtype, labels.dtype"]},{"cell_type":"markdown","metadata":{},"source":["## BNN"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-03-13T14:22:06.967029Z","iopub.status.busy":"2023-03-13T14:22:06.966450Z","iopub.status.idle":"2023-03-13T14:22:07.030749Z","shell.execute_reply":"2023-03-13T14:22:07.028863Z","shell.execute_reply.started":"2023-03-13T14:22:06.966976Z"},"trusted":true},"outputs":[],"source":["def softplus_inverse(x):\n","    '''\n","        Computes the inverse of softplus f(x) = log(exp(x) - 1) in a numerically stable way.\n","    '''\n","    return x + torch.log(-torch.expm1(-x))\n","\n","\n","class VariationalLinear(nn.Module):\n","    def __init__(\n","        self,\n","        in_features:int, out_features:int, prior_distribution, bias=True,\n","        nonlinearity=\"relu\", param=None,\n","    ):\n","        '''\n","            Args:\n","                prior:\n","                    the prior to be used.\n","                nonlinearity:\n","                    the nonlinearity that will follow the linear layer. This will be used to \n","                    calculate the gain required to properly initialize the weights.\n","                    For more information see\n","                    https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.calculate_gain.\n","                    Default value is \"relu\".\n","                param:\n","                    any parameters needed to be passed for the function that calculates the gain\n","                    (see also the \"nonlinearity\" parameter).\n","        '''\n","\n","\n","        super().__init__()\n","\n","        self.bias = bias\n","\n","        # Calculate gain\n","        gain = torch.nn.init.calculate_gain(nonlinearity=nonlinearity, param=param)\n","        # Transform the gain according to the parameterization for sigma in the paper\n","        scale = softplus_inverse(gain / torch.sqrt(torch.tensor(in_features)))\n","\n","        # Note that initialization is so that initially the sampled weights follow\n","        # N(0, gain ** 2 / in_features) distribution. This helps retain output distribution to\n","        # be closer to standard normal\n","        self.mu_weights = nn.Parameter(torch.empty(out_features, in_features).uniform_(-0.2, 0.2))\n","        self.rho_weights = nn.Parameter(torch.empty(out_features, in_features).uniform_(-5, -4))\n","\n","        if bias:\n","            # Same initialization as above\n","            self.mu_bias = nn.Parameter(torch.empty(out_features).uniform_(-0.2, 0.2))\n","            self.rho_bias = nn.Parameter(torch.empty(out_features).uniform_(-5, -4))\n","        \n","        self.prior_distribution = prior_distribution\n","\n","\n","    def forward(self, x:torch.Tensor, prune_weights=False, pruning_threshold=0.0):\n","        '''\n","            Args:\n","                x: input tensor of size (batch_size, in_features)\n","            Output:\n","                tuple (tensor, scalar tensor):\n","                    - the first element is tensor of logits of the model for the input x. The shape is (batch_size, out_features).\n","                    - the second element is the KL divergence of the model weights sampled\n","                      in the forward pass. It is a 0-dim tensor containing only one scalar.\n","        '''\n","        \n","        kl_divergence = 0\n","\n","        # Calculate W\n","        sigma_weights = F.softplus(self.rho_weights)\n","        weight_distribution = D.Normal(\n","            loc=self.mu_weights, scale=sigma_weights\n","        )\n","        W = weight_distribution.rsample()\n","        if prune_weights:\n","            snr = self.mu_weights.abs() / sigma_weights\n","            mask = snr <= pruning_threshold\n","            W[mask] = 0\n","\n","        # Calculate weight contribution to KL divergence\n","        kl_divergence += weight_distribution.log_prob(W).sum()\n","        kl_divergence -= self.prior_distribution.log_prob(W).sum()\n","\n","        # Multiply input by W\n","        out = torch.mm(x, W.T)\n","\n","        # Handle bias\n","        if self.bias:\n","            sigma_bias = F.softplus(self.rho_bias)\n","            bias_distribution = D.Normal(\n","                loc=self.mu_bias, scale=sigma_bias\n","            )\n","            b = bias_distribution.rsample()\n","            if prune_weights:\n","                snr = self.mu_bias.abs() / sigma_bias\n","                mask = snr <= pruning_threshold\n","                b[mask] = 0\n","\n","            # Add the bias\n","            out += b\n","\n","            # Calculate bias contribution to KL divergence\n","            kl_divergence += bias_distribution.log_prob(b).sum()\n","            kl_divergence -= self.prior_distribution.log_prob(b).sum()\n","\n","        return out, kl_divergence"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-03-13T14:22:07.033655Z","iopub.status.busy":"2023-03-13T14:22:07.033018Z","iopub.status.idle":"2023-03-13T14:22:07.091400Z","shell.execute_reply":"2023-03-13T14:22:07.089530Z","shell.execute_reply.started":"2023-03-13T14:22:07.033472Z"},"trusted":true},"outputs":[],"source":["class VariationalMLP(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim, prior_distribution):\n","        super().__init__()\n","\n","        self.prior_distribution = prior_distribution\n","\n","        self.layers = nn.ModuleList([\n","            VariationalLinear(\n","                in_features=input_dim, out_features=hidden_dim,\n","                prior_distribution=prior_distribution\n","            ),\n","            VariationalLinear(\n","                in_features=hidden_dim, out_features=hidden_dim,\n","                prior_distribution=prior_distribution\n","            ),\n","            VariationalLinear(\n","                in_features=hidden_dim, out_features=output_dim,\n","                prior_distribution=prior_distribution\n","            ),\n","        ])\n","    \n","    def _single_forward(self, x, prune_weights, pruning_threshold):\n","        total_kl_divergence = 0\n","        for i, layer in enumerate(self.layers):\n","            x, kl_divergence = layer(\n","                x, prune_weights=prune_weights, pruning_threshold=pruning_threshold\n","            )\n","\n","            if i < len(self.layers) - 1:\n","                x = F.relu(x)\n","\n","            total_kl_divergence += kl_divergence\n","\n","        x = x.unsqueeze(dim=1)\n","\n","        return x, total_kl_divergence\n","    \n","\n","    def forward(self, x, n_samples=1, prune_weights=False, pruning_threshold=0.0):\n","\n","        logits = []\n","        kl_divergence = 0\n","        \n","        for _ in range(n_samples):\n","            curr_logits, curr_kl_divergence = self._single_forward(\n","                x, prune_weights=prune_weights, pruning_threshold=pruning_threshold\n","            )\n","            logits.append(curr_logits)\n","            kl_divergence += curr_kl_divergence\n","\n","        logits = torch.cat(logits, axis=1)\n","        kl_divergence /= n_samples\n","    \n","        return logits, kl_divergence"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-03-13T14:22:07.097126Z","iopub.status.busy":"2023-03-13T14:22:07.095876Z","iopub.status.idle":"2023-03-13T14:22:07.145702Z","shell.execute_reply":"2023-03-13T14:22:07.144600Z","shell.execute_reply.started":"2023-03-13T14:22:07.097076Z"},"trusted":true},"outputs":[],"source":["class RegressionELBO(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, outputs, labels, kl_divergence, kl_weight):\n","        nll = self._get_neg_log_lik(y_pred=outputs, y_true=labels)\n","\n","        elbo = kl_weight * kl_divergence + nll\n","        \n","        return elbo, nll\n","\n","    \n","    def _get_neg_log_lik(self, y_true, y_pred):\n","        batched_nll = (y_pred - y_true.unsqueeze(-1))**2 / 2\n","        \n","        return batched_nll.sum(dim=0).mean(dim=0)\n"]},{"cell_type":"markdown","metadata":{"id":"UvtuXSYxTIc7"},"source":["## Environment"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-03-13T14:22:07.149159Z","iopub.status.busy":"2023-03-13T14:22:07.147504Z","iopub.status.idle":"2023-03-13T14:22:07.201653Z","shell.execute_reply":"2023-03-13T14:22:07.200443Z","shell.execute_reply.started":"2023-03-13T14:22:07.149091Z"},"id":"7OcdTTcfPicp","trusted":true},"outputs":[],"source":["class Environment:\n","\n","    def __init__(self, contexts, labels):\n","        self.contexts = contexts\n","        self.labels = labels\n","    \n","    def get_random_mushroom(self):\n","        mushroom_idx = np.random.randint(len(self.contexts))\n","\n","        return self.contexts[mushroom_idx], self.labels[mushroom_idx].item()\n","\n","    def get_agent_reward(self, edible, eaten):\n","        if not eaten:\n","            return 0\n","        if edible:\n","            return 5\n","        if torch.rand(1).item() <= 0.5:\n","            return -35\n","        return 5\n","    \n","    def get_oracle_reward(self, edible):\n","        return 5 * float(edible)\n"]},{"cell_type":"markdown","metadata":{"id":"qu8Ug8t2U2kG"},"source":["## Agent"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-03-13T14:22:07.204363Z","iopub.status.busy":"2023-03-13T14:22:07.203103Z","iopub.status.idle":"2023-03-13T14:22:07.252984Z","shell.execute_reply":"2023-03-13T14:22:07.251541Z","shell.execute_reply.started":"2023-03-13T14:22:07.204317Z"},"trusted":true},"outputs":[],"source":["def get_kl_weight(M, batch_index=-1, uniform_kl_weight=True):\n","    '''\n","        M: number of batches\n","    '''\n","\n","    kl_weight = 1 / M\n","    if not uniform_kl_weight:\n","        if batch_index == -1:\n","            raise Exception(\"Batch Index Not specified while getting Loss\")\n","\n","        # The batch_index + 1 is because we should be counting the batches\n","        # from 1 to M, not from 0 to M-1\n","        kl_weight = 2**(M - (batch_index + 1)) / (2**M - 1)\n","\n","    return kl_weight"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-03-13T14:22:07.255239Z","iopub.status.busy":"2023-03-13T14:22:07.254772Z","iopub.status.idle":"2023-03-13T14:22:07.326093Z","shell.execute_reply":"2023-03-13T14:22:07.324743Z","shell.execute_reply.started":"2023-03-13T14:22:07.255192Z"},"id":"vsAlvtviVhIc","trusted":true},"outputs":[],"source":["class AgentBNN:\n","\n","    def __init__(\n","            self, model, optimizer, batch_size, n_samples=2,\n","            uniform_kl_weight=False, buffer_size=4096, context_size=117,\n","        ):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.batch_size = batch_size\n","        self.n_samples = n_samples\n","        self.uniform_kl_weight = uniform_kl_weight\n","        print(f\"uniform_kl_weight={self.uniform_kl_weight}\")\n","        \n","        self.criterion = RegressionELBO()\n","        \n","        self.buffer_size = buffer_size\n","        self.context_action_buffer = torch.zeros(buffer_size, context_size + 2)\n","        self.reward_buffer = torch.zeros(buffer_size)\n","        \n","        self.tp = 0\n","        self.tn = 0\n","        self.fp = 0\n","        self.fn = 0\n","        \n","        self.tps = []\n","        self.tns = []\n","        self.fps = []\n","        self.fns = []\n","        \n","        self.decisions = []\n","\n","\n","    def step(self, mushroom_context):\n","        eat_action = torch.hstack([mushroom_context, torch.tensor([1, 0])]).view(1, -1)\n","        not_eat_action = torch.hstack([mushroom_context, torch.tensor([0, 1])]).view(1, -1)\n","\n","        self.model.eval()\n","        with torch.no_grad():\n","            eat_reward = self.model(eat_action, n_samples=self.n_samples)[0].mean().item()\n","            not_eat_reward = self.model(not_eat_action, n_samples=self.n_samples)[0].mean().item()\n","        \n","        # Action is to eat or not\n","        return eat_reward > not_eat_reward\n","    \n","\n","    def update_buffers(self, context_action_pair, reward, step, edible, eat):\n","        new_idx = step % self.buffer_size\n","        self.context_action_buffer[new_idx, :] = context_action_pair\n","        self.reward_buffer[new_idx] = reward\n","        \n","        # record bandit action\n","        if edible and eat:\n","            self.tp += 1\n","        elif edible and not eat:\n","            self.fn += 1\n","        elif not edible and eat:\n","            self.fp += 1\n","        else:\n","            self.tn += 1\n","        \n","        self.tps.append(self.tp)\n","        self.tns.append(self.tn)\n","        self.fps.append(self.fp)\n","        self.fns.append(self.fn)\n","        \n","        self.decisions.append(eat)\n","\n","\n","    def _get_training_dataloader(self, step):\n","        max_idx = min(step, self.buffer_size)\n","        \n","        training_context_action_pairs = self.context_action_buffer[:max_idx, :]\n","        training_rewards = self.reward_buffer[:max_idx]\n","\n","        if max_idx < self.buffer_size:\n","            indices = torch.randint(\n","                high=training_context_action_pairs.shape[0], size=(self.buffer_size, ),\n","            )\n","            training_context_action_pairs = training_context_action_pairs[indices]\n","            training_rewards = training_rewards[indices]\n","\n","        dataset = TensorDataset(training_context_action_pairs, training_rewards)\n","\n","        return DataLoader(\n","            dataset=dataset, batch_size=self.batch_size,\n","            shuffle=True, drop_last=False, num_workers=0,\n","        )\n","\n","\n","    def train(self, step):\n","        dataloader = self._get_training_dataloader(step=step)\n","\n","        running_elbo = 0\n","        running_kl = 0\n","        running_nll = 0\n","        self.model.train()\n","        for batch_idx, (x, y) in enumerate(dataloader):\n","            predicted_rewards, kl_divergence = self.model(x, n_samples=self.n_samples)\n","\n","            kl_weight = get_kl_weight(\n","                M=len(dataloader.dataset) // self.batch_size,\n","                batch_index=batch_idx,\n","                uniform_kl_weight=self.uniform_kl_weight,\n","            )\n","            elbo, nll = self.criterion(\n","                outputs=predicted_rewards, labels=y.view(-1, 1),\n","                kl_divergence=kl_divergence, kl_weight=kl_weight,\n","            )\n","\n","            self.optimizer.zero_grad()\n","            elbo.backward()\n","            self.optimizer.step()\n","\n","            running_elbo += elbo.item()\n","            running_kl += (elbo - nll).item()\n","            running_nll += nll.item()\n","\n","        return running_elbo, running_kl, running_nll"]},{"cell_type":"markdown","metadata":{"id":"-yRzb5JqVzJY"},"source":["## Trainer"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-03-13T14:26:35.842885Z","iopub.status.busy":"2023-03-13T14:26:35.841246Z","iopub.status.idle":"2023-03-13T14:26:35.903914Z","shell.execute_reply":"2023-03-13T14:26:35.902543Z","shell.execute_reply.started":"2023-03-13T14:26:35.842829Z"},"id":"zfWJOLVCVx4k","trusted":true},"outputs":[],"source":["def train_rl(n_steps, environment, agent, name, scheduler=None, checkpoint=None):\n","    print(f\"n_steps={n_steps}\")\n","\n","    cumulative_regrets = [0]\n","    elbos = []\n","    kl_divergences = []\n","    nlls = []\n","    \n","    if checkpoint is not None:\n","        print(f\"Loading checkpoint: {checkpoint}\")\n","        checkpoint = torch.load(checkpoint)\n","\n","        agent.model.load_state_dict(checkpoint['model'])\n","        agent.optimizer.load_state_dict(checkpoint['optimizer'])\n","\n","        agent = checkpoint[\"agent\"]\n","        cumulative_regrets = checkpoint[\"cumulative_regrets\"]\n","        elbos = checkpoint[\"elbos\"]\n","        kl_divergences = checkpoint[\"kl_divergences\"]\n","        nlls = checkpoint[\"nlls\"]\n","        \n","        if len(cumulative_regrets) % 10 == 0:\n","            cumulative_regrets = [0] + cumulative_regrets\n","    \n","\n","    loop = tqdm(range(1, n_steps+1), total=n_steps, leave=False)\n","    for step in loop:\n","        # Get a new mushroom\n","        mushroom_context, edible = environment.get_random_mushroom()\n","\n","        # Decide whether to eat it\n","        eat = agent.step(mushroom_context=mushroom_context)\n","    \n","        # Calculate the different reward\n","        agent_reward = environment.get_agent_reward(edible=edible, eaten=eat)\n","        oracle_reward = environment.get_oracle_reward(edible=edible)\n","\n","        # Update the buffers\n","        action = torch.Tensor([1, 0] if eat else [0, 1])\n","        agent.update_buffers(\n","            context_action_pair=torch.hstack([mushroom_context, action]),\n","            reward=agent_reward,\n","            step=step-1,\n","            edible=edible, eat=eat,\n","        )\n","\n","        # Calculate regret\n","        regret = oracle_reward - agent_reward\n","        cumulative_regrets.append(cumulative_regrets[-1] + regret)\n","\n","        elbo, kl, nll = agent.train(step=step)\n","        elbos.append(elbo)\n","        kl_divergences.append(kl)\n","        nlls.append(nll)\n","        \n","        loop.set_postfix(\n","            cumulative_regret=cumulative_regrets[-1], elbo=elbo, kl=kl, nll=nll,\n","        )\n","        \n","        if scheduler is not None:\n","            scheduler.step()\n","        \n","        # Checkpoint\n","        if step % 1000 == 0:\n","            print(f\"Step {step}: regret: {cumulative_regrets[-1]} ({len(cumulative_regrets[1:])})\")\n","            print(f\"TP: {agent.tp}, TN: {agent.tn}, FP: {agent.fp}, FN: {agent.fn}\")\n","            if scheduler is not None:\n","                print(f\"LR: {scheduler.get_last_lr()[0]}\")\n","            df = pd.DataFrame.from_dict({\n","                \"cumulative_regret\": cumulative_regrets[1:],\n","                \"elbo\": elbos,\n","                \"kl_divergence\": kl_divergences,\n","                \"nll\": nlls,\n","            })\n","            df.to_csv(f\"{name}.csv\")\n","        \n","            save_dict = {\n","                \"model\": agent.model.state_dict(),\n","                \"optimizer\": agent.optimizer.state_dict(),\n","                \"agent\": agent,\n","                \"cumulative_regrets\": cumulative_regrets,\n","                \"elbos\": elbos,\n","                \"kl_divergences\": kl_divergences,\n","                \"nlls\": nlls,\n","            }\n","            if scheduler is not None: save_dict[\"scheduler\"] = scheduler.state_dict()\n","            torch.save(save_dict, f\"checkpoint_{step}.ckpt\")\n","    \n","    return cumulative_regrets[1:], elbos, kl_divergences, nlls"]},{"cell_type":"markdown","metadata":{"id":"32ossZi1jPFK"},"source":["## Run"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-03-13T14:26:36.383260Z","iopub.status.busy":"2023-03-13T14:26:36.381999Z","iopub.status.idle":"2023-03-13T14:26:56.461262Z","shell.execute_reply":"2023-03-13T14:26:56.460348Z","shell.execute_reply.started":"2023-03-13T14:26:36.383212Z"},"id":"7xb0_chCZ6Bk","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of model parameters: 44402\n","Adam (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    capturable: False\n","    differentiable: False\n","    eps: 1e-08\n","    foreach: None\n","    fused: False\n","    lr: 5e-06\n","    maximize: False\n","    weight_decay: 0\n",")\n","scheduler=None\n","uniform_kl_weight=True\n","n_steps=18000\n","Loading checkpoint: /kaggle/input/aml-rl-bnn-checpoint-32000-v2/checkpoint_32000.ckpt\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"38a80f746aaa491ab7bcd7f4ea73ca19","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/18000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Step 10: regret: 3965.0 (32010)\n","TP: 16502, TN: 15195, FP: 196, FN: 117\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/3019259439.py\u001b[0m in \u001b[0;36mtrain_rl\u001b[0;34m(n_steps, environment, agent, name, scheduler, checkpoint)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mcumulative_regrets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcumulative_regrets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mregret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0melbo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0melbos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melbo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mkl_divergences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/3379294270.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, step)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0melbo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[1;32m    487\u001b[0m         torch.autograd.backward(\n\u001b[0;32m--> 488\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m         )\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["%%time\n","\n","# Prior\n","sigma_1 = torch.exp(-torch.tensor(0))\n","sigma_2 = torch.exp(-torch.tensor(6))\n","\n","p = 1/2\n","mixture_distribution = D.Categorical(probs=torch.tensor([p, 1 - p]))\n","component_distribution = D.Normal(\n","    loc=torch.zeros(2),\n","    scale=torch.tensor([sigma_1, sigma_2]),\n",")\n","prior_distribution = D.MixtureSameFamily(\n","    mixture_distribution=mixture_distribution, component_distribution=component_distribution\n",")\n","\n","\n","# Model\n","model = VariationalMLP(\n","    input_dim=contexts.shape[1] + 2,\n","    hidden_dim=100, output_dim=1,\n","    prior_distribution=prior_distribution\n",")\n","print(f\"Number of model parameters: {sum(p.nelement() for p in model.parameters())}\")\n","\n","\n","# Optimizer\n","optimizer = torch.optim.Adam(\n","    params=model.parameters(), lr=LEARNING_RATE,\n",")\n","print(optimizer)\n","\n","\n","# Scheduler\n","# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5000, gamma=0.5)\n","# def epoch_to_factor(epoch):\n","#     if epoch <= 5000: return 1\n","#     if epoch <= 25000: return 0.1\n","#     return 1/20\n","# scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=epoch_to_factor)\n","scheduler = None\n","print(f\"scheduler={scheduler}\")\n","\n","\n","environment = Environment(contexts=contexts, labels=labels)\n","\n","agent = AgentBNN(\n","    model=model, optimizer=optimizer,\n","    batch_size=BATCH_SIZE,\n","    buffer_size=BUFFER_SIZE,\n","    context_size=contexts.shape[1],\n","    n_samples=N_SAMPLES,\n","    uniform_kl_weight=True,\n",")\n","\n","cumulative_regrets, elbos, kl_divergences, nlls = train_rl(\n","    n_steps=N_TRAINING_STEPS,\n","    environment=environment,\n","    agent=agent,\n","    name=f\"bnn\",\n","    scheduler=scheduler,\n","    checkpoint=\"/kaggle/input/aml-rl-bnn-checpoint-32000-v2/checkpoint_32000.ckpt\",\n",")"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-03-13T14:22:37.170435Z","iopub.status.busy":"2023-03-13T14:22:37.170049Z","iopub.status.idle":"2023-03-13T14:22:37.219275Z","shell.execute_reply":"2023-03-13T14:22:37.217616Z","shell.execute_reply.started":"2023-03-13T14:22:37.170399Z"},"trusted":true},"outputs":[],"source":["# checkpoint = torch.load(\"/kaggle/input/aml-rl-bnn-checkpoint-32000/checkpoint_32000.ckpt\")\n","\n","# model.load_state_dict(checkpoint['model'])\n","# optimizer.load_state_dict(checkpoint['optimizer'])\n","\n","# agent = checkpoint[\"agent\"]\n","# cumulative_regrets = checkpoint[\"cumulative_regrets\"][1:]\n","# elbos = checkpoint[\"elbos\"]\n","# kl_divergences = checkpoint[\"kl_divergences\"]\n","# nlls = checkpoint[\"nlls\"]"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-03-13T14:22:37.222825Z","iopub.status.busy":"2023-03-13T14:22:37.221324Z","iopub.status.idle":"2023-03-13T14:22:37.294865Z","shell.execute_reply":"2023-03-13T14:22:37.292667Z","shell.execute_reply.started":"2023-03-13T14:22:37.222766Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'cumulative_regrets' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/630990729.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcumulative_regrets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'cumulative_regrets' is not defined"]}],"source":["len(cumulative_regrets)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-03-13T14:22:37.295909Z","iopub.status.idle":"2023-03-13T14:22:37.296378Z","shell.execute_reply":"2023-03-13T14:22:37.296148Z","shell.execute_reply.started":"2023-03-13T14:22:37.296126Z"},"trusted":true},"outputs":[],"source":["cumulative_regrets[-10:]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-03-13T14:22:37.299635Z","iopub.status.idle":"2023-03-13T14:22:37.300525Z","shell.execute_reply":"2023-03-13T14:22:37.300323Z","shell.execute_reply.started":"2023-03-13T14:22:37.300295Z"},"id":"HN1twnQajVvU","trusted":true},"outputs":[],"source":["plt.plot(range(1, len(cumulative_regrets) + 1), cumulative_regrets)\n","plt.yscale(\"log\")\n","plt.grid()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-03-13T14:22:37.301979Z","iopub.status.idle":"2023-03-13T14:22:37.302795Z","shell.execute_reply":"2023-03-13T14:22:37.302594Z","shell.execute_reply.started":"2023-03-13T14:22:37.302543Z"},"id":"Rt5a60L7jWFZ","trusted":true},"outputs":[],"source":["plt.plot(range(1, len(elbos) + 1), elbos, \"-o\")\n","plt.grid()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-03-13T14:22:37.304204Z","iopub.status.idle":"2023-03-13T14:22:37.304969Z","shell.execute_reply":"2023-03-13T14:22:37.304785Z","shell.execute_reply.started":"2023-03-13T14:22:37.304762Z"},"trusted":true},"outputs":[],"source":["plt.plot(range(1, len(kl_divergences) + 1), kl_divergences, \"-o\")\n","plt.grid()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-03-13T14:22:37.306362Z","iopub.status.idle":"2023-03-13T14:22:37.307136Z","shell.execute_reply":"2023-03-13T14:22:37.306929Z","shell.execute_reply.started":"2023-03-13T14:22:37.306897Z"},"trusted":true},"outputs":[],"source":["plt.plot(range(1, len(nlls) + 1), nlls, \"-o\")\n","plt.grid()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
